{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886ed769-07f9-474f-9f86-c9f1f17345e4",
   "metadata": {},
   "source": [
    "## 使用微调后的 LLaMA2-7B 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9cf61-2994-48c7-9a42-150920397a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c571fa5-aa51-495c-8b3d-d5605a02e491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangfuxin/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wangfuxin/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.48s/it]\n",
      "/home/wangfuxin/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM # 导入自动PEFT模型\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "model_dir = \"models/llama-7-int4-dolly-20250830_010107\" # 模型目录，训练完成后会生成该目录\n",
    " \n",
    "# 加载基础LLM模型与分词器\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    low_cpu_mem_usage=True, # 低内存使用\n",
    "    torch_dtype=torch.float16, # 使用半精度浮点数\n",
    "    load_in_4bit=True, # 以4位精度加载\n",
    ") \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir) # 加载分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d674d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randrange\n",
    " \n",
    " \n",
    "# 从hub加载数据集并得到一个样本\n",
    "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\") # 加载数据集\n",
    "sample = dataset[randrange(len(dataset))] # 随机选择一个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc31b800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'How can I schedule and run an effective meeting?',\n",
       " 'context': '',\n",
       " 'response': \"First make sure you have a clear goal that you want to achieve, and you can express it clearly. Decide who is required for the meeting to be successful, and the role that each participant plays. Consider sending out material that can be read in advance to prepare for the meeting, so you don't spend too much time during the meeting to bring people up to speed. During the meeting, do your best to keep the conversation on track, and don't be afraid to defer discussions for a later time. Keep an eye out on the time and make sure you leave a few minutes at the end to summarize the action items and ensure each has a clear owner and due date. Last but not least, take good notes that you can share to the team and remind everyone of the discussion.\",\n",
       " 'category': 'brainstorming'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7700c042-20cf-4ff1-8c40-a91cabeaaaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/wangfuxin/miniconda3/envs/peft/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "First make sure you have a clear goal that you want to achieve, and you can express it clearly. Decide who is required for the meeting to be successful, and the role that each participant plays. Consider sending out material that can be read in advance to prepare for the meeting, so you don't spend too much time during the meeting to bring people up to speed. During the meeting, do your best to keep the conversation on track, and don't be afraid to defer discussions for a later time. Keep an eye out on the time and make sure you leave a few minutes at the end to summarize the action items and ensure each has a clear owner and due date. Last but not least, take good notes that you can share to the team and remind everyone of the discussion.\n",
      "\n",
      "Generated instruction:\n",
      "What is the best way to prepare for a meeting and run an effective meeting?\n",
      "\n",
      "Ground truth:\n",
      "How can I schedule and run an effective meeting?\n"
     ]
    }
   ],
   "source": [
    "# 构建提示词 \n",
    "prompt = f\"\"\"### Instruction:\n",
    "Use the Input below to create an instruction, which could have been used to generate the input using an LLM. \n",
    " \n",
    "### Input:\n",
    "{sample['response']}\n",
    " \n",
    "### Response:\n",
    "\"\"\"\n",
    " \n",
    "input_ids = tokenizer( \n",
    "   prompt, \n",
    "   return_tensors=\"pt\", # 返回PyTorch张量\n",
    "   truncation=True # 截断过长的输入\n",
    "   ).input_ids.cuda() # 将输入编码为ID并移动到GPU\n",
    "\n",
    "outputs = model.generate(\n",
    "   input_ids=input_ids, # 输入ID \n",
    "   max_new_tokens=100, # 生成的最大新标记数\n",
    "   do_sample=True, # 启用采样\n",
    "   top_p=0.9, # nucleus采样的累积概率阈值\n",
    "   temperature=0.9 # 采样温度\n",
    ")\n",
    "\n",
    "print(f\"Prompt:\\n{sample['response']}\\n\") # 打印提示词\n",
    "print(f\"Generated instruction:\\n{tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]}\") # 打印生成的指令\n",
    "print(f\"Ground truth:\\n{sample['instruction']}\") # 打印真实指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ea5b0-cf32-4cc0-bd5e-fc17268992c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96515683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
